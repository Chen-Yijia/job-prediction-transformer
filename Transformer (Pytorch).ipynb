{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToWord(title):\n",
    "    target_words=[]\n",
    "    for word in title.split(' '):\n",
    "        if word != '' and word != ' ':\n",
    "            target_words.append(word)\n",
    "        \n",
    "    return target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareTrainSet():\n",
    "    with open('Book3.csv','r') as r:\n",
    "        reader=csv.reader(r)\n",
    "        index=0\n",
    "        train_set={}\n",
    "\n",
    "            \n",
    "        for row in reader:\n",
    "            person=[] \n",
    "            title_sequence=[]\n",
    "            #delete the empty element\n",
    "            for element in row:\n",
    "                if len(element) == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    person.append(element) #person: id+job_title_sequence\n",
    "            title_sequence=person[1:]      #title_sequnce: job sequence without id\n",
    "            max_length=len(title_sequence)-1\n",
    "            for i in range(1,max_length+1):\n",
    "                for j in range(0,len(title_sequence)-i):\n",
    "                    data={}\n",
    "                    data['input']=[]\n",
    "                    for k in range(j,i+j):\n",
    "                        data['input'].append(title_sequence[k])\n",
    "#                        data['input'].append(str(EOS_token))\n",
    "                    title=title_sequence[i+j]\n",
    "                    data['target']=ToWord(title)\n",
    "#                    data['target'].append(str(EOS_token))\n",
    "                    train_set[index]=data\n",
    "                    index += 1\n",
    "           \n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = PrepareTrainSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenTrainSet=len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenTrainSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wordbank & Titlebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word():\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addTrainSet(self, train_set):\n",
    "#        for word in sentence.split(' '):\n",
    "#            self.addWord(word)\n",
    "        for i in range(len(train_set)):\n",
    "            for word in train_set[i]['target']:\n",
    "                self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Title():\n",
    "    def __init__(self):\n",
    "        self.title2index = {}\n",
    "        self.title2count = {}\n",
    "        self.index2title = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_titles = 2  # Count SOS and EOS\n",
    "\n",
    "    def addTrainSet(self, train_set):\n",
    "#        for word in sentence.split(' '):\n",
    "#            self.addWord(word)\n",
    "        for i in range(len(train_set)):\n",
    "            for title in train_set[i]['input']:\n",
    "                self.addTitle(title)\n",
    "\n",
    "    def addTitle(self, title):\n",
    "        if title not in self.title2index:\n",
    "            self.title2index[title] = self.n_titles\n",
    "            self.title2count[title] = 1\n",
    "            self.index2title[self.n_titles] = title\n",
    "            self.n_titles += 1\n",
    "        else:\n",
    "            self.title2count[title] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordbank=Word()\n",
    "wordbank.addTrainSet(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlebank=Title()\n",
    "titlebank.addTrainSet(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,train_set):\n",
    "        self.train_set=train_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        input_indexes=[]\n",
    "        target_indexes=[]\n",
    "        for item in self.train_set[index]['input']:\n",
    "            input_indexes.append(titlebank.title2index[item])\n",
    "        input_indexes.append(EOS_token)\n",
    "        input_tensor = torch.tensor(input_indexes, dtype = torch.long, device = device).view(-1,1)\n",
    "        for word in self.train_set[index]['target']:\n",
    "            target_indexes.append(wordbank.word2index[word])\n",
    "        target_indexes.append(EOS_token)\n",
    "        target_tensor = torch.zeros(wordbank.n_words, dtype = torch.long, device = device)\n",
    "        for index in target_indexes:\n",
    "            target_tensor[index] = 1\n",
    "        \n",
    "        sample={'input':input_tensor, 'target':target_tensor}\n",
    "        # input_tensors:[tensor1(title),tensor2(title)....]\n",
    "        '''target_tensor: [\n",
    "        [],\n",
    "        []]'''\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_model = ninp (embedding dimension) <br>\n",
    "nhid: the dimension of the feedforward network model in nn.TransformerEncoder <br>\n",
    "nhead: the number of heads in the multiheadattention models  <br>\n",
    "nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### questions: \n",
    "1. why the decoder is ntoken? so the input and output tokens are the same?\n",
    "2. is ntokens here means the number of the words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_titles, n_words, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout) #get the positional encoder\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout) #get a layer\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers) # get the encoder\n",
    "        self.encoder = nn.Embedding(n_titles, ninp) #embedding layer\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, n_words)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_titles = titlebank.n_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48951"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = wordbank.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20187"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_titles = titlebank.n_titles\n",
    "n_words = wordbank.n_words\n",
    "ninp = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "\n",
    "model = TransformerModel(n_titles, n_words, ninp, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseFromDataset(index):\n",
    "    sample=positionsDataset[index]\n",
    "    return (sample['input'],sample['target'])\n",
    "\n",
    "positionsDataset = PositionDataset(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = [chooseFromDataset(random.randint(0,lenTrainSet-1)) for i in range(n_iters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluating_pairs = [chooseFromDataset(random.randint(0,lenTrainSet-1)) for i in range(n_iters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train( ) and evaluate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    n_words = wordbank.n_words\n",
    "    \n",
    "    for iter_time in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter_time - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_tensor)\n",
    "\n",
    "        loss = criterion(output.view(n_words,-1), target_tensor)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if iter_time % log_interval == 0 and iter_time > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} iters | '\n",
    "                  'lr {:02.2f} | ms/iter {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, iter_time, n_iters, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_model, evaluating_pairs):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    n_words = wordbank.n_words\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iter_time in range(1, n_iters + 1):\n",
    "            training_pair = training_pairs[iter_time - 1]\n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "\n",
    "            output = eval_model(input_tensor)\n",
    "            output_flat = output.view(n_words,-1)\n",
    "            total_loss += len(input_tensor) * criterion(output_flat, target_tensor).item()\n",
    "    return total_loss / len(evaluating_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 3 # The number of epochs\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2000 iters | lr 5.00 | ms/iter 90.55 | loss  1.15 | ppl     3.15\n",
      "| epoch   1 |   400/ 2000 iters | lr 5.00 | ms/iter 85.98 | loss  1.00 | ppl     2.71\n",
      "| epoch   1 |   600/ 2000 iters | lr 5.00 | ms/iter 87.06 | loss  1.00 | ppl     2.72\n",
      "| epoch   1 |   800/ 2000 iters | lr 5.00 | ms/iter 84.96 | loss  1.02 | ppl     2.77\n",
      "| epoch   1 |  1000/ 2000 iters | lr 5.00 | ms/iter 81.73 | loss  0.95 | ppl     2.58\n",
      "| epoch   1 |  1200/ 2000 iters | lr 5.00 | ms/iter 80.89 | loss  0.97 | ppl     2.63\n",
      "| epoch   1 |  1400/ 2000 iters | lr 5.00 | ms/iter 79.86 | loss  0.98 | ppl     2.67\n",
      "| epoch   1 |  1600/ 2000 iters | lr 5.00 | ms/iter 79.81 | loss  0.94 | ppl     2.57\n",
      "| epoch   1 |  1800/ 2000 iters | lr 5.00 | ms/iter 80.36 | loss  0.97 | ppl     2.65\n",
      "| epoch   1 |  2000/ 2000 iters | lr 5.00 | ms/iter 80.15 | loss  0.83 | ppl     2.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 173.51s | valid loss  4.83 | valid ppl   124.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 2000 iters | lr 4.51 | ms/iter 79.50 | loss  0.93 | ppl     2.52\n",
      "| epoch   2 |   400/ 2000 iters | lr 4.51 | ms/iter 79.39 | loss  0.94 | ppl     2.55\n",
      "| epoch   2 |   600/ 2000 iters | lr 4.51 | ms/iter 80.17 | loss  0.96 | ppl     2.60\n",
      "| epoch   2 |   800/ 2000 iters | lr 4.51 | ms/iter 81.53 | loss  1.00 | ppl     2.73\n",
      "| epoch   2 |  1000/ 2000 iters | lr 4.51 | ms/iter 79.01 | loss  0.93 | ppl     2.52\n",
      "| epoch   2 |  1200/ 2000 iters | lr 4.51 | ms/iter 81.17 | loss  0.99 | ppl     2.70\n",
      "| epoch   2 |  1400/ 2000 iters | lr 4.51 | ms/iter 79.29 | loss  0.98 | ppl     2.67\n",
      "| epoch   2 |  1600/ 2000 iters | lr 4.51 | ms/iter 80.31 | loss  0.94 | ppl     2.56\n",
      "| epoch   2 |  1800/ 2000 iters | lr 4.51 | ms/iter 80.26 | loss  0.98 | ppl     2.65\n",
      "| epoch   2 |  2000/ 2000 iters | lr 4.51 | ms/iter 81.31 | loss  0.84 | ppl     2.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 167.92s | valid loss  4.80 | valid ppl   121.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 2000 iters | lr 4.29 | ms/iter 83.88 | loss  0.92 | ppl     2.51\n",
      "| epoch   3 |   400/ 2000 iters | lr 4.29 | ms/iter 84.87 | loss  0.92 | ppl     2.52\n",
      "| epoch   3 |   600/ 2000 iters | lr 4.29 | ms/iter 86.89 | loss  0.96 | ppl     2.62\n",
      "| epoch   3 |   800/ 2000 iters | lr 4.29 | ms/iter 88.36 | loss  1.08 | ppl     2.95\n",
      "| epoch   3 |  1000/ 2000 iters | lr 4.29 | ms/iter 90.40 | loss  0.91 | ppl     2.48\n",
      "| epoch   3 |  1200/ 2000 iters | lr 4.29 | ms/iter 83.06 | loss  0.93 | ppl     2.54\n",
      "| epoch   3 |  1400/ 2000 iters | lr 4.29 | ms/iter 83.75 | loss  0.95 | ppl     2.60\n",
      "| epoch   3 |  1600/ 2000 iters | lr 4.29 | ms/iter 91.28 | loss  0.89 | ppl     2.43\n",
      "| epoch   3 |  1800/ 2000 iters | lr 4.29 | ms/iter 82.95 | loss  0.94 | ppl     2.56\n",
      "| epoch   3 |  2000/ 2000 iters | lr 4.29 | ms/iter 82.79 | loss  0.80 | ppl     2.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 178.51s | valid loss  4.61 | valid ppl   100.08\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, evaluating_pairs)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_pairs = [chooseFromDataset(random.randint(0,lenTrainSet-1)) for i in range(n_iters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  4.61 | test ppl   100.08\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, testing_pairs)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pair = chooseFromDataset(random.randint(0,lenTrainSet-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15011],\n",
       "         [    1]]), tensor([0, 1, 0,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = test_pair[0]\n",
    "target_tensor = test_pair[1]\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = input_tensor.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15011,     1]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100],\n",
       "        [200],\n",
       "        [102]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input3 = torch.tensor([100,200,102]).view(-1,1)\n",
    "input3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20187])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  3.2953,   0.1085,  -1.6837,  ...,   3.4385,   1.5464,   1.6353]],\n",
       "\n",
       "        [[ -1.7891,  -2.7430,  -3.5916,  ..., -13.7187, -15.8490, -18.4089]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(input_tensor)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  3.2953,   0.1085,  -1.6837,  ...,   3.4385,   1.5464,   1.6353],\n",
       "         [ -1.7877,  -2.7437,  -3.5929,  ..., -13.7170, -15.8496, -18.4093]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2=model(input2)\n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 20187])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 20187])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1041, -0.0123, -0.5805,  ...,  0.8220, -0.3597, -0.1910]],\n",
       "\n",
       "        [[ 0.9940, -0.0144, -0.5152,  ...,  0.7483, -0.3791, -0.1980]],\n",
       "\n",
       "        [[ 0.9922, -0.0142, -0.5130,  ...,  0.7491, -0.3768, -0.1954]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3 = model (input3)\n",
    "output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 20187])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModelNew(nn.Module):\n",
    "\n",
    "    def __init__(self, n_titles, n_words, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModelNew, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout) #get the positional encoder\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout) #get a layer\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers) # get the encoder\n",
    "        self.encoder = nn.Embedding(n_titles, ninp) #embedding layer\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, n_words)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output_encoder = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output_encoder)\n",
    "        return src,output_encoder,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_titles = titlebank.n_titles\n",
    "n_words = wordbank.n_words\n",
    "ninp = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model1 = TransformerModelNew(n_titles, n_words, ninp, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor=input_tensor.view(1,-1)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15011,     1]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "src,output_encoder,output = model1(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "src: tensor([[[-5.4347e-02, -3.4511e-01,  1.2058e+00,  2.5655e-01,  0.0000e+00,\n",
      "           2.8661e+00,  1.4727e-02,  1.5741e+00,  1.3153e+00,  2.4396e+00,\n",
      "          -1.1892e+00,  8.0882e-01,  0.0000e+00,  0.0000e+00,  8.6663e-01,\n",
      "           2.4342e+00,  1.6432e+00,  2.8729e+00, -0.0000e+00,  0.0000e+00,\n",
      "           1.2965e+00, -2.7127e-01, -0.0000e+00,  1.7280e+00,  1.4355e+00,\n",
      "           1.9397e+00,  1.4039e+00,  0.0000e+00,  0.0000e+00,  1.9300e+00,\n",
      "          -1.5940e+00,  0.0000e+00,  4.0013e-01,  5.0341e-01,  1.5805e-01,\n",
      "           0.0000e+00,  1.6739e+00,  0.0000e+00,  0.0000e+00, -3.0044e-01,\n",
      "           1.3160e+00,  0.0000e+00,  1.6506e+00,  0.0000e+00,  9.5599e-01,\n",
      "           6.6824e-01, -0.0000e+00,  2.7596e+00, -0.0000e+00, -3.8271e-01,\n",
      "          -4.7592e-01,  1.0277e+00,  1.1673e+00, -4.4270e-01,  1.1207e+00,\n",
      "           2.0761e+00, -0.0000e+00,  1.2975e+00, -8.4151e-01,  0.0000e+00,\n",
      "           1.0235e+00,  0.0000e+00, -4.9217e-01,  1.7472e+00, -2.3958e-01,\n",
      "           8.7226e-01,  3.4101e-01,  0.0000e+00,  0.0000e+00,  2.7048e+00,\n",
      "           8.6970e-01,  6.0349e-01, -0.0000e+00,  5.8114e-02, -1.4915e+00,\n",
      "          -2.8056e-01, -5.9803e-01,  2.8983e+00, -1.5811e+00,  6.4299e-01,\n",
      "          -1.3895e+00, -2.6399e-01,  1.6781e+00,  0.0000e+00,  2.6153e-01,\n",
      "           1.2860e+00, -4.8303e-02,  9.1374e-01, -1.5620e+00,  8.0391e-01,\n",
      "           0.0000e+00,  2.1654e+00, -1.4818e+00,  0.0000e+00,  1.7649e+00,\n",
      "           0.0000e+00,  1.1245e+00,  2.0647e+00, -0.0000e+00,  2.7635e+00,\n",
      "           7.3600e-01,  2.6355e+00, -1.7058e+00,  1.0581e-01, -9.2732e-01,\n",
      "           1.3800e-01, -6.6832e-01,  1.3741e+00,  5.2367e-01,  8.5955e-01,\n",
      "          -0.0000e+00, -0.0000e+00,  5.1576e-01, -3.9028e-01, -8.2943e-01,\n",
      "           0.0000e+00, -1.0078e+00,  9.3588e-01, -1.1835e+00,  2.4561e+00,\n",
      "           3.3531e-01,  2.6803e+00, -3.0743e-02,  2.1399e+00, -7.1131e-01,\n",
      "           8.7160e-01,  0.0000e+00,  0.0000e+00,  1.5337e+00,  2.6486e+00,\n",
      "           4.0533e-01,  2.5532e+00, -7.2972e-01,  2.8147e+00,  6.8869e-01,\n",
      "           3.2355e-01, -0.0000e+00, -3.6148e-01,  2.0048e-01,  2.5198e+00,\n",
      "           9.5100e-01,  1.9196e+00, -1.2870e+00,  4.5333e-01, -1.1814e+00,\n",
      "          -1.8026e-01, -4.3592e-01,  1.6122e+00,  3.5804e-01, -1.9716e-01,\n",
      "           6.4709e-01,  3.3237e-01,  7.9770e-01,  8.3076e-01,  7.9417e-01,\n",
      "           2.4097e+00, -1.4955e+00,  1.7844e+00, -1.1111e+00, -3.8689e-01,\n",
      "           1.5230e-02, -2.1034e-03,  0.0000e+00,  2.7014e+00, -4.0931e-01,\n",
      "           0.0000e+00,  6.9837e-01,  2.2364e+00,  1.3838e+00,  2.5783e+00,\n",
      "          -1.1647e+00,  1.6535e+00, -0.0000e+00,  1.1376e+00, -1.5612e+00,\n",
      "           2.2485e+00, -1.3174e+00,  2.5284e+00, -1.7391e+00, -2.2609e-01,\n",
      "           1.0819e+00,  0.0000e+00,  5.7962e-01,  1.2547e+00, -8.2155e-01,\n",
      "           1.9333e+00, -5.5475e-01, -3.3982e-01, -6.1923e-01,  1.4693e+00,\n",
      "           6.3627e-01, -4.2991e-01, -1.0661e+00,  7.7988e-01,  2.0078e-01,\n",
      "           5.3688e-01,  5.3179e-02,  3.4844e-01, -1.0374e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  2.4531e-01,  0.0000e+00,  1.1643e+00,\n",
      "           1.9461e+00,  1.3334e+00,  1.9542e+00,  0.0000e+00,  2.5827e+00,\n",
      "          -0.0000e+00,  1.9301e+00,  1.4069e+00,  1.6560e+00,  1.2627e-01,\n",
      "           1.9918e+00,  1.3354e-02,  1.0444e+00,  2.2707e+00,  0.0000e+00,\n",
      "          -0.0000e+00,  1.5241e+00, -0.0000e+00,  4.9753e-01, -0.0000e+00,\n",
      "           1.3986e-01, -1.1513e+00, -4.6169e-01, -1.0751e-01,  0.0000e+00,\n",
      "           7.3095e-01,  8.4660e-01,  0.0000e+00,  2.0449e+00,  1.8512e-01,\n",
      "          -0.0000e+00,  0.0000e+00,  3.3162e-01,  1.2784e+00,  1.9877e-01,\n",
      "           0.0000e+00,  1.5738e+00,  1.5976e+00,  2.8357e-01, -6.0900e-01,\n",
      "           0.0000e+00,  1.6640e+00,  0.0000e+00,  8.3065e-01,  0.0000e+00,\n",
      "          -1.6189e+00, -1.2851e-01, -9.4978e-01,  2.3976e+00, -1.6011e+00,\n",
      "           0.0000e+00,  0.0000e+00,  2.6111e-02, -0.0000e+00, -1.5354e-01,\n",
      "           2.3627e-01,  3.8549e-01,  1.6244e+00,  8.2138e-01, -9.2955e-01,\n",
      "           1.4289e+00, -1.1821e+00,  1.7431e+00,  4.0689e-01,  0.0000e+00,\n",
      "          -1.3075e+00,  9.4929e-01,  1.2078e+00,  2.7755e+00,  1.8052e+00,\n",
      "           0.0000e+00,  4.5949e-01,  6.2336e-01,  0.0000e+00, -2.7855e-01,\n",
      "           1.3523e+00,  1.5578e+00,  1.4430e+00,  2.9512e-01,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  2.8336e+00, -1.1607e+00,  1.6835e+00,\n",
      "           0.0000e+00,  1.7448e+00,  5.9943e-02,  1.4835e+00, -2.4374e-01,\n",
      "           2.5657e+00,  1.3085e+00,  4.2671e-01, -0.0000e+00,  1.7077e+00,\n",
      "          -8.6116e-01,  1.1604e+00,  2.6170e-01,  1.6542e+00,  1.6869e+00,\n",
      "           1.9966e+00, -1.4259e+00,  2.4554e+00,  1.1613e+00,  2.8680e+00,\n",
      "          -8.7019e-01,  9.0993e-01, -1.1187e+00,  1.8439e+00,  1.1829e+00,\n",
      "           1.5465e+00,  0.0000e+00,  2.7314e+00, -6.8963e-02,  0.0000e+00,\n",
      "           1.3754e-01,  2.7898e+00,  4.9351e-01, -1.9004e-01, -1.2522e+00,\n",
      "           0.0000e+00, -1.1799e+00,  1.3446e+00, -1.2183e+00, -4.9859e-01,\n",
      "           9.1146e-01,  0.0000e+00,  1.1253e+00,  0.0000e+00, -1.4519e+00,\n",
      "           2.2656e+00,  5.8204e-01,  1.1132e+00, -1.4764e+00, -1.6963e-01,\n",
      "          -1.8695e-01,  1.5760e+00, -0.0000e+00,  8.2407e-01, -1.1341e+00,\n",
      "           0.0000e+00,  1.7546e+00, -3.6189e-01, -2.0251e-01,  1.9569e-01,\n",
      "          -1.7371e+00,  1.5111e+00, -2.3484e-01,  8.6735e-01,  4.0571e-02,\n",
      "          -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7851e+00,\n",
      "           1.2782e-01,  8.1516e-01,  6.5505e-01,  2.2695e+00,  1.6754e+00,\n",
      "          -4.1305e-01, -1.6666e+00,  2.9982e+00,  1.3629e+00,  3.4712e-01,\n",
      "          -6.5896e-01,  0.0000e+00, -1.2729e+00,  8.2644e-01, -1.0173e+00,\n",
      "           0.0000e+00, -1.3321e+00, -4.8535e-01, -1.5533e+00,  2.7152e+00,\n",
      "          -7.3930e-01,  1.7853e+00,  2.9818e-01,  3.0496e-01,  1.5787e+00,\n",
      "           2.8193e+00,  5.7111e-01,  0.0000e+00,  1.6436e+00,  5.4127e-01,\n",
      "          -1.3837e-01,  2.0739e+00,  6.0885e-01,  0.0000e+00,  0.0000e+00,\n",
      "           2.1975e+00, -3.3115e-01,  2.3526e+00, -6.9790e-01,  1.7549e+00]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "output_encoder: tensor([[[ 5.4920e-01, -1.7053e+00,  8.2111e-01,  9.5568e-02,  8.9878e-01,\n",
      "           3.1384e+00, -1.0062e+00,  1.1242e+00,  1.3651e+00,  2.7308e+00,\n",
      "          -1.3875e-01,  1.5307e-01, -8.5563e-01,  1.1167e-01, -1.9025e-01,\n",
      "          -1.0187e-01, -6.5839e-03,  1.8801e+00,  1.3795e+00, -1.2523e+00,\n",
      "          -1.2578e+00, -6.2238e-02, -9.6986e-01,  1.5601e+00,  7.3733e-01,\n",
      "           1.5567e+00,  7.1717e-01, -1.2887e+00, -2.8907e-01,  2.7595e-01,\n",
      "          -2.4765e-01, -5.1582e-01,  1.2845e+00, -1.5238e-01, -1.0190e+00,\n",
      "          -7.3617e-01,  1.0956e+00,  4.4649e-01,  2.2646e-01,  3.8025e-01,\n",
      "           2.1093e-01,  1.7872e-01,  7.6471e-01, -8.9276e-01,  1.9040e+00,\n",
      "          -8.1803e-02,  4.6090e-01,  2.1535e+00, -4.5290e-01,  2.1099e-02,\n",
      "          -8.6253e-01, -1.0648e-01, -9.4776e-01, -2.4116e-02, -6.6225e-02,\n",
      "           1.9598e+00,  9.3445e-01, -6.1918e-01, -7.2460e-01, -3.6550e-01,\n",
      "           1.4266e-01, -8.2182e-01, -8.0958e-01,  9.7478e-01, -1.9466e-01,\n",
      "          -1.2165e+00, -4.2455e-01,  5.2451e-01,  2.0648e-01, -5.6493e-01,\n",
      "          -9.8344e-01,  3.4889e-01,  4.6539e-01,  6.1934e-01, -1.8841e+00,\n",
      "          -2.1490e+00, -6.1136e-01,  2.5255e+00, -1.3327e+00, -2.5738e-01,\n",
      "          -2.0917e+00, -1.0292e+00, -1.4422e-01, -2.6795e-01, -4.2098e-03,\n",
      "           6.1203e-01, -6.3309e-01,  3.0898e-01, -1.4494e+00,  6.6710e-02,\n",
      "          -9.6108e-01,  1.6755e+00,  2.2351e-01, -4.2821e-01,  9.4701e-01,\n",
      "           1.0029e-03, -1.9307e-01,  1.3181e+00, -5.8387e-01,  1.0057e+00,\n",
      "           6.9022e-01,  7.4492e-01, -1.6054e+00, -1.2910e-01, -5.8846e-01,\n",
      "          -2.5351e-02, -1.2459e+00,  6.1912e-01, -1.6355e-02,  3.9474e-01,\n",
      "           8.6459e-01, -2.5337e-01, -1.3321e+00,  2.4050e-01,  3.2844e-01,\n",
      "          -1.2012e+00, -5.0703e-01, -5.1105e-02, -1.0147e+00,  1.9318e+00,\n",
      "           1.6925e-01,  1.4931e+00,  1.2877e+00,  1.0224e+00,  3.7525e-01,\n",
      "          -6.7380e-01, -6.8068e-01, -7.2879e-01, -2.8096e-01,  1.8924e+00,\n",
      "           6.2273e-02,  1.0836e+00, -1.1068e+00,  1.6888e+00, -9.9412e-01,\n",
      "          -3.4445e-02, -1.1220e+00, -3.2025e-01, -1.8501e+00,  5.4321e-01,\n",
      "          -9.6909e-01, -2.9976e-05, -1.8069e+00, -2.9019e-01, -4.5809e-01,\n",
      "          -5.2049e-01,  2.4242e-01,  7.1869e-01,  4.5529e-01, -8.4602e-01,\n",
      "           6.0562e-02,  9.2039e-01,  1.7477e-02,  1.0042e+00, -2.7835e-02,\n",
      "           5.1351e-01, -5.7649e-01,  6.6832e-01, -7.0318e-01, -1.2752e+00,\n",
      "          -4.8050e-01, -8.9014e-02, -4.0002e-01,  1.7961e+00,  1.4557e+00,\n",
      "          -6.0057e-01,  1.8909e-01,  3.6206e-02,  3.6844e-01,  8.5829e-02,\n",
      "           1.3854e-01,  7.4364e-01, -5.0238e-01,  1.0278e+00, -2.2692e+00,\n",
      "           3.7852e-01, -1.4682e+00,  4.8844e-01, -1.4186e+00,  6.4455e-01,\n",
      "           6.0317e-01, -2.4284e-01, -5.9566e-01,  3.5719e-01, -2.8621e-01,\n",
      "           1.4145e+00, -6.8202e-01, -4.5664e-01, -6.8412e-01,  1.0768e+00,\n",
      "          -5.8961e-01, -1.0264e+00, -3.0255e+00,  4.0582e-01,  1.8004e+00,\n",
      "           8.9283e-01,  3.1495e-01, -2.0221e-01, -2.5629e+00, -5.4070e-01]],\n",
      "\n",
      "        [[-1.1735e-01, -1.8543e+00, -8.9411e-02, -1.0545e-01,  1.0556e+00,\n",
      "           1.1981e+00, -9.3843e-02,  1.5029e+00, -1.7387e-01,  1.3603e+00,\n",
      "           8.1827e-01,  7.7096e-01, -3.2911e-01,  1.1631e+00, -1.1105e-01,\n",
      "          -3.0912e-02,  1.0581e-01,  6.3370e-01,  1.5942e+00, -8.2985e-01,\n",
      "          -1.2249e+00,  6.4753e-01, -1.2601e+00,  5.0560e-01,  1.2781e-01,\n",
      "           1.5727e-01, -1.7842e+00, -8.8473e-01, -9.0284e-01, -1.5496e-01,\n",
      "           6.9534e-01,  3.4895e-01, -3.4712e-01,  3.2218e-01, -1.2236e+00,\n",
      "          -1.3929e-01, -1.5623e-01,  1.2542e-01,  4.3388e-01,  4.4856e-01,\n",
      "          -4.9582e-01,  1.7619e+00,  6.7881e-01, -6.4539e-01, -2.2630e-01,\n",
      "          -1.0037e+00,  2.3887e+00, -6.6917e-01,  3.0386e-01, -3.1158e-01,\n",
      "          -7.1533e-01, -1.5072e+00, -1.6459e+00,  7.6204e-01, -1.5829e+00,\n",
      "           4.0183e-01,  9.0833e-01, -8.1008e-01, -1.0816e+00, -2.4952e-01,\n",
      "           8.3641e-02,  1.5377e-01,  3.0655e-02,  3.8049e-01, -1.4244e+00,\n",
      "          -9.9849e-01, -7.0744e-01,  5.6603e-01,  1.0025e+00, -5.0916e-01,\n",
      "          -1.9610e+00,  6.4280e-01,  6.4201e-01,  1.2510e+00, -3.1589e-03,\n",
      "          -1.9658e+00, -1.2812e+00,  4.4239e-01, -9.9254e-01, -8.4005e-01,\n",
      "           1.5439e-01,  1.1287e+00,  2.5773e-01, -2.5501e-02,  5.9375e-02,\n",
      "          -2.8910e-01,  7.9278e-01,  1.9622e+00, -2.3198e+00, -1.4461e-02,\n",
      "          -3.7080e-02,  8.0383e-01,  5.0692e-01,  1.1044e-02, -7.1669e-01,\n",
      "           1.4552e+00, -1.3346e+00,  3.7392e-01,  1.1253e-01,  7.5478e-01,\n",
      "          -8.5380e-01,  1.0689e-01, -1.0183e+00,  1.3098e+00,  1.6027e+00,\n",
      "           9.7756e-01, -2.8953e+00,  1.5929e+00,  1.7878e-01,  1.0302e+00,\n",
      "          -6.8853e-01,  1.0487e+00, -1.0460e+00,  2.1241e+00,  7.2514e-01,\n",
      "          -1.8276e-01, -3.1783e-01,  1.6280e+00, -1.8700e-01,  1.1115e+00,\n",
      "          -4.8259e-01,  1.6283e+00,  1.5176e+00, -9.2913e-01,  5.0779e-01,\n",
      "          -1.3791e+00, -6.8290e-01,  1.3147e-02, -1.9251e+00, -4.1896e-01,\n",
      "           9.7915e-01,  6.8800e-01, -2.1525e-01, -1.6320e-01, -1.8937e+00,\n",
      "           1.0621e+00, -1.1450e+00,  1.0541e+00, -7.2102e-01, -2.4595e-01,\n",
      "          -7.5700e-01,  3.2229e-01, -6.5152e-01,  5.8862e-01, -5.2637e-01,\n",
      "           1.1223e+00,  1.2429e-03, -8.4427e-01, -6.3712e-01,  7.8005e-01,\n",
      "          -1.1530e+00,  9.0778e-01, -1.4727e+00,  5.3813e-01, -4.2462e-01,\n",
      "           1.3471e-01,  1.3495e+00, -1.3462e-01, -1.6168e-01, -3.1427e-01,\n",
      "          -1.1931e+00, -3.3050e-02,  9.4150e-01,  7.7034e-01,  2.0570e+00,\n",
      "          -1.7692e+00, -1.0649e+00, -1.6545e-01,  4.4932e-01, -1.3933e+00,\n",
      "           2.0976e-01, -5.5291e-01, -8.7098e-01,  6.5122e-01, -6.8036e-01,\n",
      "          -1.4985e+00, -1.1967e+00, -7.4694e-01, -1.6324e+00,  2.2343e+00,\n",
      "          -2.6830e-01,  1.3988e+00,  3.7693e-01,  4.3503e-01,  1.0406e+00,\n",
      "           1.9319e+00,  8.8845e-01,  1.9322e-01,  1.3386e-01,  2.8883e-01,\n",
      "          -7.2041e-01,  4.7390e-02, -7.1526e-01,  4.9599e-01,  1.8941e-01,\n",
      "           2.0334e+00,  2.7886e-01,  2.7680e-01, -2.5608e+00,  9.6566e-01]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "output: tensor([[[ 0.3761,  0.5701,  1.1905,  ..., -0.0370,  0.0971, -0.2813]],\n",
      "\n",
      "        [[-0.5297,  1.2876,  1.0453,  ..., -0.7530,  0.2568, -0.0789]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "src: {src}\n",
    "output_encoder: {output_encoder}\n",
    "output: {output}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "src: torch.Size([1, 2, 200])\n",
      "output_encoder: torch.Size([1, 2, 200])\n",
      "output: torch.Size([1, 2, 20187])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "src: {src.shape}\n",
    "output_encoder: {output_encoder.shape}\n",
    "output: {output.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20187])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_adjusted = output.view(-1,n_words)\n",
    "output_adjusted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_print = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateFromDataset(index):\n",
    "    each_set=train_set[index]\n",
    "    sample=positionsDataset[index]\n",
    "    return (each_set['input'],each_set['target'],sample['input'],sample['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "printing_pairs=[evaluateFromDataset(random.randint(0,lenTrainSet-1)) for i in range(n_print)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalPrint(eval_model, input_tensor):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    n_words = wordbank.n_words\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        output = eval_model(input_tensor)\n",
    "        output_flat = output.view(-1,n_words)\n",
    "        softmax = nn.LogSoftmax(dim=0)\n",
    "        adjusted = torch.add(output_flat[0],output_flat[1])\n",
    "        final = softmax(adjusted)\n",
    "        decoded_words = []\n",
    "        while True:\n",
    "            topv, topi = final.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(wordbank.index2word[topi.item()])\n",
    "                \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(model, n=10):\n",
    "    for i in range(n):\n",
    "        pair = printing_pairs[i]\n",
    "        print('input sequence: ', pair[0])\n",
    "        target_title = ' '.join(pair[1])\n",
    "        print('target title: ', target_title)\n",
    "        output_words = evalPrint(model, pair[2])\n",
    "        output_title = ' '.join(output_words)\n",
    "        print('output title: ', output_title)\n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence:  ['Manager / Consultant', 'Account Manager', 'Senior Manager, Client Services', 'Group Account Manager', 'Unit Head']\n",
      "target title:  Account Director\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-c9ad02bc816e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-120-6ee019654660>\u001b[0m in \u001b[0;36mevaluateRandomly\u001b[0;34m(model, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtarget_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target title: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moutput_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output title: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-0903da4f2968>\u001b[0m in \u001b[0;36mevalPrint\u001b[0;34m(eval_model, input_tensor)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdecoded_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEOS_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mdecoded_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<EOS>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluateRandomly(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
